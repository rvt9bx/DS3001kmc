{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cfc23963-2cc5-4f1d-8278-fb1b2026afc5",
      "metadata": {
        "id": "cfc23963-2cc5-4f1d-8278-fb1b2026afc5"
      },
      "source": [
        "## Assignment: $k$ Means Clustering\n",
        "\n",
        "## **Do two questions.**\n",
        "\n",
        "`! git clone https://www.github.com/DS3001/kmc`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://www.github.com/DS3001/kmc"
      ],
      "metadata": {
        "id": "zvMJYQaycfUa",
        "outputId": "c05d9d93-f3e4-4f33-b388-b857f4ab5353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zvMJYQaycfUa",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kmc'...\n",
            "warning: redirecting to https://github.com/DS3001/kmc.git/\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 25 (delta 2), reused 1 (delta 1), pack-reused 21\u001b[K\n",
            "Receiving objects: 100% (25/25), 5.04 MiB | 17.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FnAaGM-7cxV_"
      },
      "id": "FnAaGM-7cxV_",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "85dae156-b49b-4f43-bc42-ad1589132891",
      "metadata": {
        "id": "85dae156-b49b-4f43-bc42-ad1589132891"
      },
      "source": [
        "# **Q1.**\n",
        "This question is a case study for $k$ means clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Load the `airbnb_hw.csv` data. Clean `Price` along with `Beds`, `Number of Reviews`, and `Review Scores Rating`.\n",
        "2. Maxmin normalize the data and remove any `nan`'s (`KMeans` from `sklearn` doesn't accept `nan` input).\n",
        "3. Use `sklearn`'s `KMeans` module to cluster the data by `Beds`, `Number of Reviews`, and `Review Scores Rating` for `k=6`.\n",
        "4. Use `seaborn`'s `.pairplot()` to make a grid of scatterplots that show how the clustering is carried out in multiple dimensions.\n",
        "5. Use `.groupby` and `.describe` to compute the average price for each cluster. Which clusters have the highest rental prices?\n",
        "6. Use a scree plot to pick the number of clusters and repeat steps 4 and 5."
      ],
      "metadata": {
        "id": "FPvKnACkcovg"
      },
      "id": "FPvKnACkcovg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PT 1"
      ],
      "metadata": {
        "id": "241I8HErcqFA"
      },
      "id": "241I8HErcqFA"
    },
    {
      "cell_type": "code",
      "source": [
        "# load airbnb data\n",
        "\n",
        "df = pd.read_csv('/content/kmc/data/airbnb_hw.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "8y_Rmxuhcimp"
      },
      "id": "8y_Rmxuhcimp",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean price\n",
        "\n",
        "df['Price'] = df['Price'].str.replace(',','')  # take out commas\n",
        "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')  # coerce to numeric"
      ],
      "metadata": {
        "id": "Xm9ujzPZdZcn"
      },
      "id": "Xm9ujzPZdZcn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean beds\n",
        "\n",
        "df['Beds'] = pd.to_numeric(df['Beds'], errors='coerce')  # coerce to numeric"
      ],
      "metadata": {
        "id": "HtfZ45ocdzm7"
      },
      "id": "HtfZ45ocdzm7",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean number of reviews\n",
        "\n",
        "df['Number Of Reviews'].dtype\n",
        "df['Number Of Reviews'].value_counts()\n",
        "# Number of Reviews is already an int so we don't need to transform it"
      ],
      "metadata": {
        "id": "ycp1y0dNd_Ki",
        "outputId": "90919f43-14a6-4be3-b11c-53b7cff138ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ycp1y0dNd_Ki",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      7814\n",
              "1      3572\n",
              "2      2457\n",
              "3      1764\n",
              "4      1382\n",
              "       ... \n",
              "216       1\n",
              "191       1\n",
              "213       1\n",
              "178       1\n",
              "130       1\n",
              "Name: Number Of Reviews, Length: 205, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clean review scores rating\n",
        "\n",
        "df['Review Scores Rating'].dtype\n",
        "df['Review Scores Rating'].isnull().sum()"
      ],
      "metadata": {
        "id": "yVPetItMfyRb",
        "outputId": "b174c3df-9629-4a98-e33a-8c780634125e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yVPetItMfyRb",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8323"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26523935-9e8f-4377-920c-6f65605c0e31",
      "metadata": {
        "id": "26523935-9e8f-4377-920c-6f65605c0e31"
      },
      "source": [
        "**Q2.** This is a question about $k$ means clustering. We want to investigate how adjusting the \"noisiness\" of the data impacts the quality of the algorithm and the difficulty of picking $k$.\n",
        "\n",
        "1. Run the code below, which creates four datasets: `df0_125`, `df0_25`, `df0_5`, `df1_0`, and `df2_0`. Each data set is created by increasing the amount of `noise` (standard deviation) around the cluster centers, from `0.125` to `0.25` to `0.5` to `1.0` to `2.0`.\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def createData(noise,N=50):\n",
        "    np.random.seed(100) # Set the seed for replicability\n",
        "    # Generate (x1,x2,g) triples:\n",
        "    X1 = np.array([np.random.normal(1,noise,N),np.random.normal(1,noise,N)])\n",
        "    X2 = np.array([np.random.normal(3,noise,N),np.random.normal(2,noise,N)])\n",
        "    X3 = np.array([np.random.normal(5,noise,N),np.random.normal(3,noise,N)])\n",
        "    # Concatenate into one data frame\n",
        "    gdf1 = pd.DataFrame({'x1':X1[0,:],'x2':X1[1,:],'group':'a'})\n",
        "    gdf2 = pd.DataFrame({'x1':X2[0,:],'x2':X2[1,:],'group':'b'})\n",
        "    gdf3 = pd.DataFrame({'x1':X3[0,:],'x2':X3[1,:],'group':'c'})\n",
        "    df = pd.concat([gdf1,gdf2,gdf3],axis=0)\n",
        "    return df\n",
        "\n",
        "df0_125 = createData(0.125)\n",
        "df0_25 = createData(0.25)\n",
        "df0_5 = createData(0.5)\n",
        "df1_0 = createData(1.0)\n",
        "df2_0 = createData(2.0)\n",
        "```\n",
        "\n",
        "2. Make scatterplots of the $(X1,X2)$ points by group for each of the datasets. As the `noise` goes up from 0.125 to 2.0, what happens to the visual distinctness of the clusters?\n",
        "3. Create a scree plot for each of the datasets. Describe how the level of `noise` affects the scree plot (particularly the presence of a clear \"elbow\") and your ability to definitively select a $k$.\n",
        "4. Explain the intuition of the elbow, using this numerical simulation as an example."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "870041b4-204b-4bc4-bf8a-3fe2f8734a58",
      "metadata": {
        "id": "870041b4-204b-4bc4-bf8a-3fe2f8734a58"
      },
      "source": [
        "**Q3.** We looked at computer vision with $k$NN in a previous question. Can $k$ means clustering correctly group digits, even if we don't know which symbols are which?\n",
        "\n",
        "1. To load the data, run the following code in a chunk:\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "df = mnist.load_data('minst.db')\n",
        "train,test = df\n",
        "X_train, y_train = train\n",
        "X_test, y_test = test\n",
        "```\n",
        "The `y_test` and `y_train` vectors, for each index `i`, tell you want number is written in the corresponding index in `X_train[i]` and `X_test[i]`. The value of `X_train[i]` and `X_test[i]`, however, is a 28$\\times$28 array whose entries contain values between 0 and 256. Each element of the matrix is essentially a \"pixel\" and the matrix encodes a representation of a number. To visualize this, run the following code to see the first ten numbers:\n",
        "```\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(edgeitems=30, linewidth=100000)\n",
        "for i in range(5):\n",
        "    print(y_test[i],'\\n') # Print the label\n",
        "    print(X_test[i],'\\n') # Print the matrix of values\n",
        "    plt.contourf(np.rot90(X_test[i].transpose())) # Make a contour plot of the matrix values\n",
        "    plt.show()\n",
        "```\n",
        "OK, those are the data: Labels attached to handwritten digits encoded as a matrix.\n",
        "\n",
        "2. What is the shape of `X_train` and `X_test`? What is the shape of `X_train[i]` and `X_test[i]` for each index `i`? What is the shape of `y_train` and `y_test`?\n",
        "3. Use Numpy's `.reshape()` method to covert the training and testing data from a matrix into an vector of features. So, `X_test[index].reshape((1,784))` will convert the $index$-th element of `X_test` into a $28\\times 28=784$-length row vector of values, rather than a matrix. Turn `X_train` into an $N \\times 784$ matrix $X$ that is suitable for scikit-learn's kNN classifier where $N$ is the number of observations and $784=28*28$ (you could use, for example, a `for` loop).\n",
        "4. Use $k$ means clustering on the reshaped `X_test` data with `k=10`.  \n",
        "5. Cross tabulate the cluster assignments with the true labels for the test set values. How good is the correspondence? What proportion of digits are clustered correctly? Which digits are the hardest to distinguish from one another? Can $k$MC recover the latent digits 0 to 9, without even knowing what those digits were?\n",
        "6. If you use a scree plot to determine the number of clusters $k$, does it pick 10 (the true number of digits), or not? If it fails to pick $k=10$, which digits does it tend to combine into the same classification?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}